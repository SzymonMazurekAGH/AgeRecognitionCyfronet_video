{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Creating one unified .csv file containing frames from labeled data made via DeepLabCut\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN, A3TGCN, GConvLSTM,TGCN\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "import networkx as nx\n",
    "import torch_geometric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data_path = r\"dlc_project_2022_08_02\\labeled-data\"\n",
    "dst_path = r'new_ds_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateUnifiedCsv(object):\n",
    "    \n",
    "    \"\"\"Class to transform many csv files created by DeepLabCut labeling into one, unified CSV which\n",
    "    describes frames and source videos.\n",
    "    If a frame contains missing label, the frame will NOT be included into merged dataset.\"\"\"\n",
    "\n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        pass\n",
    "\n",
    "    def make_unified_dataset(self, source_path : str, dst_path : str) -> None:\n",
    "        \"\"\"Method to create .csv file containing the dataset.\n",
    "            Args types:\n",
    "            source_path (str) - Location of labeled-data folder in the DeepLabCut project.\n",
    "            dst_pat (str) - Path where the file should be saved (ending with filename.csv).\n",
    "        \"\"\"\n",
    "        self.source_path = source_path\n",
    "        self.dst_path = dst_path\n",
    "        buffer_dict = {}\n",
    "        \n",
    "        for n,folder in enumerate(os.listdir(self.source_path)):\n",
    "\n",
    "            frame_label = re.split(\"\\_\",folder)[0]\n",
    "            folderpath = os.path.join(self.source_path,folder)\n",
    "            folder_files = os.listdir(folderpath)\n",
    "            csv_file = str(next(filter(lambda a: '.csv' in a, folder_files)))\n",
    "            csv_path = os.path.join(folderpath,csv_file)\n",
    "            labeled_data = pd.read_csv(csv_path)\n",
    "            buffer_dict[f'vid_id_{n}'] = folder\n",
    "\n",
    "            if n == 0:\n",
    "\n",
    "                buffer_dict['bodyparts'] = labeled_data.loc[0][3:].values\n",
    "                buffer_dict['coords'] = labeled_data.loc[1][3:].values\n",
    "\n",
    "            for index,row in labeled_data.iterrows():\n",
    "\n",
    "                if index >=2:\n",
    "\n",
    "                    if True in pd.isna(labeled_data.loc[index][3:].values):\n",
    "                        print(\"Skipping bad index\")\n",
    "\n",
    "                    else:\n",
    "                        buffer_dict[labeled_data.loc[index][2]] = labeled_data.loc[index][3:].values\n",
    "\n",
    "        new_df = pd.DataFrame(buffer_dict,index = None)\n",
    "        new_df = new_df.transpose()\n",
    "        new_df.to_csv(self.dst_path)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_ds_csv_merger = CreateUnifiedCsv()\n",
    "new_ds_csv_merger.make_unified_dataset(labeled_data_path,dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateJsonDataset(object):\n",
    "\n",
    "    \"\"\"Dataset consisting of key feature points coordinates. Data is extracted from \n",
    "    .csv files created using DeepLabCut, a software for labeling video frames. \n",
    "    One video should have corresponding .csv file, with the filename starting with age of a dog followed by\n",
    "    underscore (Example: adult_1.csv). Every set of keypoint for given frame will be associated with the \n",
    "    corresponding age group label.\"\"\"\n",
    "\n",
    "    def __init__(self)-> None:\n",
    "        \n",
    "        pass\n",
    "\n",
    "    def _extract_features_and_timesteps(self) -> None:\n",
    "        # Method to extract features and labels from .csv files defining dataset created with DeepLabCut.\n",
    "        # .csv files must be stored in the folders created during labeling with DeepLabCut, every folder has to be named\n",
    "        # age_[...].csv, where age is a name describing the category in which given film belongs to\n",
    "        label_list = {}\n",
    "        data_list = {}\n",
    "        labeled_data = pd.read_csv(self.path_to_dataset)\n",
    "\n",
    "        for index, row in labeled_data.iterrows():\n",
    "\n",
    "            tuple_list = []\n",
    "\n",
    "            if index == 0:\n",
    "\n",
    "                vid_name = row[1]\n",
    "                data_list[vid_name] = []\n",
    "                label_list[vid_name] = re.split(\"\\_\",vid_name)[0]\n",
    "\n",
    "            if index >= 3: ## skip first rows\n",
    "\n",
    "                row = row.values[1:]\n",
    "\n",
    "                for i in range(1,len(row),2):\n",
    "\n",
    "                    try: \n",
    "                        x_coord = round(float((row[i-1])),4) ## extract x coordinate\n",
    "                        y_coord = round(float((row[i])),4) ## extract y coordinate\n",
    "                        assert np.isnan(x_coord) == False, f\"Nan coordinate x found in row: {index+1}\"\n",
    "                        assert np.isnan(y_coord) == False, f\"Nan coordinate y found in row: {index+1}\"\n",
    "                        tuple_list.append((x_coord, y_coord)) ## write every coordinate pair into list\n",
    "                        \n",
    "                    except: \n",
    "                        ## when during iteration a name of next video is found in the rows, new label is assigned\n",
    "                        vid_name = row[1]\n",
    "                        data_list[vid_name] = []\n",
    "                        label_list[vid_name] = re.split(\"\\_\",vid_name)[0]\n",
    "                        pass\n",
    "                    \n",
    "                if tuple_list:\n",
    "\n",
    "                    data_list[vid_name].append((tuple_list))\n",
    "\n",
    "        self._features = data_list\n",
    "        self._labels = label_list\n",
    "        \n",
    "    def _assign_bodypart_to_node(self) -> None:\n",
    "        # Method to assign bodypart name to a node\n",
    "        node_dict = {}\n",
    "        n = 0\n",
    "        dataframe = pd.read_csv(self.path_to_dataset) ## read the dataset\n",
    "        bodypart_row = list(dataframe.iloc[1][1:]) # extract row containing bodypart names\n",
    "\n",
    "        for bp_idx in range(1,len(bodypart_row),2):\n",
    "\n",
    "            node_dict[bodypart_row[bp_idx]] = n # assign bodypart to a node number\n",
    "            n += 1\n",
    "        self._node_ids = node_dict\n",
    "        \n",
    "    def _create_fc_graph_edges(self) -> None:\n",
    "        # Method to create fully connected undirected graph.\n",
    "        # Can only be called after _assign_bodypart_to_node() is called\n",
    "        edges = []\n",
    "\n",
    "        for i in range(len(self._node_ids)):\n",
    "            for j in range(len(self._node_ids)):\n",
    "                edges.append((i,j))\n",
    "\n",
    "        self._edges = edges\n",
    "            \n",
    "    def create_json_dataset(self, path_to_csv : str, save_path : str) -> None:\n",
    "        \"\"\"Method to create .json file containing the dataset.\n",
    "            Args types:\n",
    "            save_path (str) - path where the file should be saved (ending with filename.json)\n",
    "            path_to_csv (str) - path to csv file containing dataset\n",
    "        \"\"\"\n",
    "        self.path_to_dataset = path_to_csv\n",
    "        self._extract_features_and_timesteps()\n",
    "        self._assign_bodypart_to_node()\n",
    "        self._create_fc_graph_edges()\n",
    "\n",
    "        create_graph_ds = {\n",
    "        \"edges\" : self._edges,\n",
    "        \"node_ids\" : self._node_ids,\n",
    "        \"features\" : self._features,\n",
    "        \"labels\" : self._labels\n",
    "        }\n",
    "\n",
    "        json_dataset = json.dumps(create_graph_ds)\n",
    "        with open(save_path, \"w\") as outfile:\n",
    "            outfile.write(json_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Add variable for class constructor that defines if the user wants to input edges created independetly \n",
    "# (in form extracted from nx graph from dr. Wielgosz code) or to use the one provided in json dataset (fully connected undirected graph)\n",
    "#TODO Add variable for class constructor that defines if user wants to flatten the graph (if the features have more than 1 dimension, create \n",
    "# separate node for every dimension (eg. tuple to be mapped into two separate, connected nodes.)). The user can still pass his own adjecency \n",
    "# matrix that will be reshaped into the one corresponding to the flattened graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JsonDatasetLoader(object):\n",
    "\n",
    "    \"\"\"Creates a loader for Dog Age keypoints video dataset.\n",
    "\n",
    "     Args types:\n",
    "            path_to_dataset (str) - path to .json dataset\n",
    "            one_hot (bool) - whether to use one hot label encoding\n",
    "            sparse (bool) - whether to use sparse label encoding\n",
    "            timestep (int) - number of frames in a single sample\n",
    "            overlap (int) - amount of overlapping consecutive frames between the clips\n",
    "            faltten_features (bool) - whether to flatten every single node feature into separate node\n",
    "            (resulting in number of nodes equal to num_nodes*len(node_features)).\n",
    "            custom_edges : (np.array) - np.array of shape [num_nodes,2] containing pairs of integers describing connections\n",
    "            between corresponding nodes\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 path_to_dataset : str,\n",
    "                 one_hot : bool = False, \n",
    "                 sparse : bool = True,\n",
    "                 timestep : int = 4, \n",
    "                 overlap : int = 0,\n",
    "                 faltten_features : bool = False,\n",
    "                 custom_edges : np.array = None) -> None:\n",
    "\n",
    "        if  (one_hot and sparse):\n",
    "            raise AttributeError(\"Cannot get one hot and sparse labels at once!\")\n",
    "        \n",
    "\n",
    "        self._path_to_dataset = path_to_dataset\n",
    "        self._timestep = timestep\n",
    "        self._overlap = overlap\n",
    "        self._sparse = sparse\n",
    "        self._one_hot = one_hot\n",
    "        self._flatten_features = faltten_features\n",
    "        self._custom_edges = custom_edges\n",
    "        self._open_json_dataset() \n",
    "        if custom_edges:\n",
    "            assert custom_edges.ndim == 2, \"Custom edges must have 2 dmiensions!\"\n",
    "            assert custom_edges.shape[1] == 2, \"2-nd dimension of custom edges must be 2!\"\n",
    "            assert custom_edges.shape[0] == len(self._dataset[\"node_ids\"]), \"Dataset was created for \\n\"\n",
    "            \"different number of nodes than specified in custom edges!\"\n",
    "\n",
    "    def _open_json_dataset(self):\n",
    "        self._dataset = json.load(open(self._path_to_dataset))\n",
    "\n",
    "    def _get_edges(self):\n",
    "        \n",
    "        if self._custom_edges is None:\n",
    "            if not self._flatten_features:\n",
    "                self._edges = np.array(self._dataset[\"edges\"]).T\n",
    "            else:\n",
    "                num_of_nodes = len(self._dataset[\"node_ids\"])\n",
    "                num_of_features = len(list(self._dataset[\"features\"].values())[0][0][0]) #epic oneliner lol\n",
    "                G = nx.complete_graph(num_of_nodes*num_of_features)\n",
    "                a = torch_geometric.utils.from_networkx(G)\n",
    "                self._edges = np.array(a)[0][1].numpy()\n",
    "        else:\n",
    "            if not self._flatten_features:\n",
    "                self._edges = self._custom_edges.T\n",
    "            #else: TODO\n",
    "\n",
    "    def _get_edge_weights(self):\n",
    "        self._edge_weights = np.ones(self._edges.shape[1])\n",
    "\n",
    "    def _get_labels_and_features(self):\n",
    "\n",
    "        features_dict = self._dataset[\"features\"]\n",
    "        labels_dict = self._dataset[\"labels\"]\n",
    "\n",
    "        for n,key in enumerate(features_dict.keys()):\n",
    "\n",
    "            vid_label = labels_dict[key]\n",
    "            features_reshaped = np.array(features_dict[key]).swapaxes(0,2).swapaxes(0,1)\n",
    "\n",
    "            if n == 0: ## create features and lables list for the first video\n",
    "                self._features = [features_reshaped[:,:,i:i+self._timestep] \n",
    "                for i in range(0, features_reshaped.shape[2] - self._timestep, self._timestep - self._overlap)\n",
    "                ]\n",
    "                self._labels = [vid_label for _ in range(len(self._features))]\n",
    "\n",
    "            else: ## append features and labels with the data for each consecutive video in the dataset\n",
    "\n",
    "                temp_features = [features_reshaped[:,:,i:i+self._timestep] \n",
    "                for i in range(0,features_reshaped.shape[2] - self._timestep, self._timestep - self._overlap)\n",
    "                ]\n",
    "                temp_labels = [vid_label for _ in range(len(temp_features))]\n",
    "                self._features = self._features + temp_features\n",
    "                self._labels = self._labels + temp_labels\n",
    "\n",
    "            if self._flatten_features:\n",
    "                self._features = [np.reshape(item,(item.shape[0]*item.shape[1], item.shape[2])) \n",
    "                for item in self._features\n",
    "                ] ## TODO sprawdzić czy to działa bo wygląda źle\n",
    "\n",
    "        if self._one_hot is True:\n",
    "            \n",
    "            self._labels = np.array(self._labels)\n",
    "            self._labels = self._labels.reshape((self._labels.shape[0],1))\n",
    "            self._labels = list(OneHotEncoder(sparse=False).fit_transform(self._labels))\n",
    "\n",
    "        elif self._sparse is True:\n",
    "\n",
    "            self._labels = np.array(self._labels)\n",
    "            self._labels = self._labels.reshape((self._labels.shape[0],1))\n",
    "            self._labels = list(OrdinalEncoder().fit_transform(self._labels))\n",
    "\n",
    "    def get_dataset(self) -> StaticGraphTemporalSignal:\n",
    "        \"\"\"Creating the Dog age video keypoints data iterator. The iterator yelds static,\n",
    "        fully connected, unweighted graphs with bodyparts assigned to given node and label for every\n",
    "        set of features. A set of features describes given clip (collection of following frames).\n",
    "        Features are of shape [nodes,features,timesteps].\n",
    "\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)* - The Dog Age Video dataset.\n",
    "        \"\"\"\n",
    "               \n",
    "        self._get_edges()\n",
    "        self._get_edge_weights()\n",
    "        self._get_labels_and_features()\n",
    "\n",
    "        dataset = StaticGraphTemporalSignal(\n",
    "        self._edges, self._edge_weights, self._features, self._labels\n",
    "        )\n",
    "        \n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIMESTEP = 5\n",
    "new_loader = JsonDatasetLoader(\"json_datasets\\sample_2.json\", one_hot= False, sparse= True, timestep = TIMESTEP, overlap = 0)\n",
    "valid_dataset = new_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = nx.DiGraph()\n",
    "g.add_nodes_from(list(range(0,18 * 3)))\n",
    "for i in range(0, 3):\n",
    "    g.add_edge((i * 18) + 10,(i * 18) + 9)\n",
    "    g.add_edge((i * 18) + 9,(i * 18) + 10)\n",
    "    g.add_edge((i * 18) + 9,(i * 18) + 8)\n",
    "    g.add_edge((i * 18) + 8, (i * 18) + 9)\n",
    "    g.add_edge((i * 18) + 8, (i * 18) + 1)\n",
    "    g.add_edge((i * 18) + 1, (i * 18) + 8)\n",
    "    g.add_edge((i * 18) + 13, (i * 18) + 12)\n",
    "    g.add_edge((i * 18) + 12, (i * 18) + 13)\n",
    "    g.add_edge((i * 18) + 12, (i * 18) + 11)\n",
    "    g.add_edge((i * 18) + 11, (i * 18) + 12)\n",
    "    g.add_edge((i * 18) + 11, (i * 18) + 1)\n",
    "    g.add_edge((i * 18) + 1, (i * 18) + 11)\n",
    "    g.add_edge((i * 18) + 1, (i * 18) + 5)\n",
    "    g.add_edge((i * 18) + 5, (i * 18) + 1)\n",
    "    g.add_edge((i * 18) + 5, (i * 18) + 6)\n",
    "    g.add_edge((i * 18) + 6, (i * 18) + 5)\n",
    "    g.add_edge((i * 18) + 6, (i * 18) + 7)\n",
    "    g.add_edge((i * 18) + 7, (i * 18) + 6)\n",
    "    g.add_edge((i * 18) + 1, (i * 18) + 2)\n",
    "    g.add_edge((i * 18) + 2, (i * 18) + 1)\n",
    "    g.add_edge((i * 18) + 2, (i * 18) + 3)\n",
    "    g.add_edge((i * 18) + 3, (i * 18) + 2)\n",
    "    g.add_edge((i * 18) + 3, (i * 18) + 4)\n",
    "    g.add_edge((i * 18) + 4, (i * 18) + 3)\n",
    "    g.add_edge((i * 18) + 1, (i * 18) + 0)\n",
    "    g.add_edge((i * 18) + 0, (i * 18) + 1)\n",
    "    g.add_edge((i * 18) + 0, (i * 18) + 15)\n",
    "    g.add_edge((i * 18) + 15, (i * 18) + 0)\n",
    "    g.add_edge((i * 18) + 0, (i * 18) + 14)\n",
    "    g.add_edge((i * 18) + 14, (i * 18) + 0)\n",
    "    g.add_edge((i * 18) + 16, (i * 18) + 14)\n",
    "    g.add_edge((i * 18) + 14, (i * 18) + 16)\n",
    "    g.add_edge((i * 18) + 17, (i * 18) + 15)\n",
    "    g.add_edge((i * 18) + 15, (i * 18) + 17)\n",
    "\n",
    "for i in range(0, 18):\n",
    "    g.add_edge(i, i + 18)\n",
    "    g.add_edge(i + 18, i)\n",
    "    g.add_edge(i, i + 36)\n",
    "    g.add_edge(i + 36, i)\n",
    "    g.add_edge(i +36, i + 18)\n",
    "    g.add_edge(i + 18, i + 36)\n",
    "\n",
    "# A = nx.edges(g)\n",
    "a = torch_geometric.utils.from_networkx(g)\n",
    "a = np.array(a)[0][1].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.conv1d_1 = torch.nn.Conv1d(2,1,1,stride=1,padding=0)\n",
    "        self.recurrent = DCRNN(node_features, 32, 1)\n",
    "        self.fc1 = torch.nn.Linear(224, 1)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.squeeze = torch.squeeze\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.conv1d_1(x)\n",
    "        h = torch.squeeze(h)\n",
    "        h = self.recurrent(h, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.flatten(h)\n",
    "        h = self.fc1(h)\n",
    "        h = torch.sigmoid(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ATGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features, periods):\n",
    "        super(ATGCN, self).__init__()\n",
    "        self.recurrent = A3TGCN(node_features, 32, periods)\n",
    "        self.linear = torch.nn.Linear(224, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = nn.Flatten(start_dim=0)(h)\n",
    "        h = self.linear(h)\n",
    "        h = torch.sigmoid(h)\n",
    "        return h\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "def get_accuracy(y_true, y_prob):\n",
    "    \"\"\"Binary accuracy calculation\"\"\"\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_prob = np.where(y_prob <= 0.5, 0, y_prob)\n",
    "    y_prob = np.where(y_prob > 0.5, 1, y_prob)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_true, y_prob)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#model = ATGCN(node_features = 2, periods = TIMESTEP).to(device)\n",
    "model = RecurrentGCN(TIMESTEP).to(device)\n",
    "\n",
    "loss_fn =  nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(1000)):\n",
    "    epoch_loss = 0.0\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "    for time, snapshot in enumerate(valid_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        ##loss\n",
    "        loss = loss_fn(y_hat,snapshot.y)\n",
    "        epoch_loss += loss\n",
    "        ## get preds & gorund truth\n",
    "        preds.append(y_hat.detach().numpy())\n",
    "        ground_truth.append(snapshot.y.numpy())\n",
    "        ##backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    ## calculate acc\n",
    "    acc = get_accuracy(ground_truth,preds)\n",
    "\n",
    "    print(f'Epoch: {epoch}', f'Epoch accuracy: {acc}', f'Epoch loss: {epoch_loss.detach().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_and_timesteps(dataset_files_path):\n",
    "    \"\"\"Code for debugging the method in the loader class. Not important now.\"\"\"\n",
    "    \n",
    "    label_list = {}\n",
    "    data_list = {}\n",
    "        \n",
    "    labeled_data = pd.read_csv(dataset_files_path)\n",
    "    for index, row in labeled_data.iterrows():\n",
    "        tuple_list = []\n",
    "        if index == 0:\n",
    "            vid_name = row[1]\n",
    "            data_list[vid_name] = []\n",
    "            label_list[vid_name] = re.split(\"\\_\",vid_name)[0]\n",
    "        if index >= 3: ## skip first rows\n",
    "            row = row.values[1:]\n",
    "           #print(row) ## take only coordinates from the rows\n",
    "            assert (len(row))%2 == 0, f\"Odd number of coordinates in row {index + 2}, maybe some coordinates are missing\"\n",
    "            for i in range(1,len(row),2):\n",
    "                try: \n",
    "                    x_coord = round(float((row[i-1])),4) ## extract x coordinate\n",
    "                    y_coord = round(float((row[i])),4) ## extract y coordinate\n",
    "                    assert np.isnan(x_coord) == False, f\"Nan coordinate x found in row: {index+1}\"\n",
    "                    assert np.isnan(y_coord) == False, f\"Nan coordinate y found in row: {index+1}\"\n",
    "                    tuple_list.append((x_coord, y_coord)) ## write every coordinate pair into list\n",
    "                    \n",
    "                except:\n",
    "                    vid_name = row[1]\n",
    "                    data_list[vid_name] = []\n",
    "                    label_list[vid_name] = re.split(\"\\_\",vid_name)[0]\n",
    "                    pass\n",
    "                  \n",
    "            if tuple_list:\n",
    "                data_list[vid_name].append((tuple_list))\n",
    "    features = data_list\n",
    "    labels = label_list\n",
    "    return features, labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('CyfroML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23bb462f369faf32515ef68bcf08a22f46ef4bd3e7610215b17cb366918e9729"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

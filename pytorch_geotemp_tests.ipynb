{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import torchmetrics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "from torch_geometric_temporal.nn.recurrent import DCRNN\n",
    "from torch_geometric_temporal.dataset import ChickenpoxDatasetLoader\n",
    "from torch_geometric_temporal.signal import StaticGraphTemporalSignal\n",
    "from torch_geometric_temporal.signal import temporal_signal_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CreateGraphDataset(object):\n",
    "\n",
    "    \"\"\"Dataset consisting of key feature points coordinates. Data is extracted from \n",
    "    .csv files created using DeepLabCut, a software for labeling video frames. \n",
    "    One video should have corresponding .csv file, with the filename starting with age of a dog followed by\n",
    "    underscore (Example: adult_1.csv). Every set of keypoint for given frame will be associated with the \n",
    "    corresponding age group label.\"\"\"\n",
    "    def __init__(self, path_to_dataset : str)-> None:\n",
    "        self.path_to_dataset = path_to_dataset\n",
    "        self._get_files_and_fileapths()\n",
    "        \n",
    "    \n",
    "    def _get_files_and_fileapths(self) -> None:\n",
    "        # Method creating helper variables for file operations\n",
    "        dataset_files_path = []\n",
    "        self.dataset_files = os.listdir(self.path_to_dataset)\n",
    "        for n, file in enumerate(self.dataset_files):\n",
    "            dataset_files_path.append(os.path.join(self.path_to_dataset,file))\n",
    "        self.dataset_files_path = dataset_files_path\n",
    "\n",
    "    def _extract_features_and_timesteps(self) -> None:\n",
    "        # Method to extract features and labels from .csv files defining dataset created with #DeepLabCut.\n",
    "        # Csv has to be named age_n.csv, where age is a age category and n is the number of occurence of \n",
    "        # this category in the dataset\n",
    "        \n",
    "        label_list = []\n",
    "        data_list = []\n",
    "            \n",
    "        for n,datafile in enumerate(self.dataset_files_path):     \n",
    "            labeled_data = pd.read_csv(datafile)\n",
    "            for index, row in labeled_data.iterrows():\n",
    "                tuple_list = []\n",
    "                if index >= 2: ## skip first row\n",
    "                    row = labeled_data.iloc[index].values[3:] ## take only coordinates from the rows\n",
    "                    assert (len(row))%2 == 0, f\"Odd number of coordinates in row {index + 2}, maybe some coordinates are missing\"\n",
    "                    for i in range(1,len(row),2): \n",
    "                        x_coord = round(float((row[i-1])),4) ## extract x coordinate\n",
    "                        y_coord = round(float((row[i])),4) ## extract y coordinate\n",
    "                        assert np.isnan(x_coord) == False, f\"Nan coordinate x found in row: {index+1}\"\n",
    "                        assert np.isnan(y_coord) == False, f\"Nan coordinate y found in row: {index+1}\"\n",
    "                        tuple_list.append(((x_coord), (y_coord))) ## write every coordinate pair into list\n",
    "                    data_list.append(tuple_list) ## write list of pairs for a given timestep to a list\n",
    "                    label_list.append([re.split(\"\\_\",self.dataset_files[n])[0]]) ## add a label to every frame\n",
    "        self._features = data_list\n",
    "        self._labels = label_list\n",
    "\n",
    "    \n",
    "\n",
    "    def _assign_bodypart_to_node(self) -> None:\n",
    "        # Method to assign bodypart name to a node\n",
    "\n",
    "        def next_number(number_list):\n",
    "            #helper method\n",
    "            for x in number_list:\n",
    "                yield x\n",
    "\n",
    "        node_dict = {}\n",
    "        dataframe = pd.read_csv(self.dataset_files_path[0]) ## read any file in the dataset\n",
    "        bodypart_row = dataframe.iloc[0][3:] # extract row containing bodypart names\n",
    "        bodyparts_num = int(len(bodypart_row)/2) # count bodyparts\n",
    "        num_generator = next_number(list(range(bodyparts_num)))                     ## yeah, I know it's terrible, really\n",
    "        for bp_idx in range(0,len(bodypart_row),2):\n",
    "            bodypart = str(bodypart_row[bp_idx]) # extract bodypart name\n",
    "            node_dict[bodypart] = next(num_generator) # assign bodypart to a node number\n",
    "        self._node_ids = node_dict\n",
    "\n",
    "    def _create_fc_graph_edges(self) -> None:\n",
    "        # Method to create fully connected undirected graph.\n",
    "        # Can only be called after _node_itds attribute is assigned\n",
    "        edges = []\n",
    "        for i in range(len(self._node_ids)):\n",
    "            for j in range(len(self._node_ids)):\n",
    "                edges.append((i,j))\n",
    "        self._edges = edges\n",
    "        \n",
    "    def create_json_dataset(self, save_path :str) -> None:\n",
    "        \"\"\"Method to create .json file containing the dataset.\n",
    "            Args types:\n",
    "            * **save_path** *(str)* - Path where the file should be saved (ending with filename.json).\n",
    "        \"\"\"\n",
    "        self._extract_features_and_timesteps()\n",
    "        self._assign_bodypart_to_node()\n",
    "        self._create_fc_graph_edges()\n",
    "\n",
    "        create_graph_ds = {\n",
    "        \"edges\" : self._edges,\n",
    "        \"node_ids\" : self._node_ids,\n",
    "        \"features\" : self._features,\n",
    "        \"labels\" : self._labels\n",
    "        }\n",
    "\n",
    "        json_dataset = json.dumps(create_graph_ds)\n",
    "        with open(save_path, \"w\") as outfile:\n",
    "            outfile.write(json_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkeleonDatasetLoader(object):\n",
    "    \"\"\"Creates a loader for Dog Age keypoints video dataset. User can specify the encoding \n",
    "    of the labels (one hot, sparse or original). Sparse encoding assigns class numbers following the\n",
    "    alphanumerical order.\n",
    "\n",
    "       Args types:\n",
    "        * **dataset_path:\n",
    "\"\"\"\n",
    "    def __init__(self,dataset_path: str, one_hot : bool = False, sparse : bool = True) -> None:\n",
    "        self._dataset_path = dataset_path\n",
    "        self._one_hot = one_hot\n",
    "        self._sparse = sparse\n",
    "        self._open_json_dataset()\n",
    "        self._get_labels_and_features()\n",
    "\n",
    "\n",
    "    def _open_json_dataset(self):\n",
    "        self._dataset = json.load(open(self._dataset_path))\n",
    "\n",
    "    def _get_edges(self):\n",
    "        self._edges = np.array(self._dataset[\"edges\"]).T\n",
    "\n",
    "    def _get_edge_weights(self):\n",
    "        self._edge_weights = np.ones(self._edges.shape[1])\n",
    "\n",
    "    def _get_labels_and_features(self):\n",
    "        self._features = np.array(self._dataset[\"features\"])\n",
    "        if self._one_hot is True:\n",
    "            labels = np.array(self._dataset[\"labels\"])\n",
    "            self._labels = OneHotEncoder(sparse=False).fit_transform(labels)\n",
    "        elif self._sparse is True:\n",
    "            labels = np.array(self._dataset[\"labels\"])\n",
    "            self._labels = OrdinalEncoder().fit_transform(labels)\n",
    "        else:\n",
    "            self._labels = np.array(self._dataset[\"labels\"])\n",
    "        \n",
    "    def get_dataset(self):\n",
    "        \"\"\"Returning the Dog age video keypoints data iterator.\n",
    "\n",
    "        Return types:\n",
    "            * **dataset** *(StaticGraphTemporalSignal)* - The Dog Age Video dataset.\n",
    "        \"\"\"\n",
    "        self._get_edges()\n",
    "        self._get_edge_weights()\n",
    "        self._get_labels_and_features()\n",
    "        dataset = StaticGraphTemporalSignal(\n",
    "            self._edges, self._edge_weights, self._features, self._labels\n",
    "        )\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentGCN(torch.nn.Module):\n",
    "    def __init__(self, node_features):\n",
    "        super(RecurrentGCN, self).__init__()\n",
    "        self.recurrent = DCRNN(node_features, 128, 1)\n",
    "        self.fc1 = torch.nn.Linear(128 * 4, 1)\n",
    "        self.flatten = torch.nn.Flatten(start_dim=0)\n",
    "        self.squeeze = torch.squeeze\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        h = self.recurrent(x, edge_index, edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.flatten(h)\n",
    "        h = self.fc1(h)\n",
    "        h = torch.sigmoid(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_creator = CreateGraphDataset(\"dataset\")\n",
    "dataset_creator.create_json_dataset(\"json_datasets\\sample.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_loader = SkeleonDatasetLoader(\"json_datasets\\sample.json\", sparse= True, one_hot=False)\n",
    "my_dataset = new_loader.get_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_true, y_prob):\n",
    "    \"\"\"Binary accuracy calculation\"\"\"\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_prob = np.where(y_prob <= 0.5, 0, y_prob)\n",
    "    y_prob = np.where(y_prob > 0.5, 1, y_prob)\n",
    "\n",
    "    accuracy = metrics.accuracy_score(y_true, y_prob)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model = RecurrentGCN(node_features = 2)\n",
    "\n",
    "loss_fn =  nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(500)):\n",
    "    epoch_loss = 0.0\n",
    "    preds = []\n",
    "    ground_truth = []\n",
    "    for time, snapshot in enumerate(my_dataset):\n",
    "        y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "        ##loss\n",
    "        loss = loss_fn(y_hat,snapshot.y)\n",
    "        epoch_loss += loss\n",
    "        ## get preds & gorund truth\n",
    "        preds.append(y_hat.detach().numpy())\n",
    "        ground_truth.append(snapshot.y.numpy())\n",
    "        ##backprop\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    ## calculate acc\n",
    "    acc = get_accuracy(ground_truth,preds)\n",
    "\n",
    "    print(f'Epoch: {epoch}', f'Epoch accuracy: {acc}', f'Epoch loss: {epoch_loss.detach().numpy()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 1.0 Test loss: 0.015035977237857878\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.eval()\n",
    "eval_loss = 0\n",
    "preds = []\n",
    "ground_truth = []\n",
    "for time, snapshot in enumerate(my_dataset):\n",
    "    y_hat = model(snapshot.x, snapshot.edge_index, snapshot.edge_attr)\n",
    "    loss = loss_fn(y_hat,snapshot.y)\n",
    "    eval_loss += loss.detach().numpy()\n",
    "    preds.append(y_hat.detach().numpy())\n",
    "    ground_truth.append(snapshot.y.numpy())\n",
    "\n",
    "test_acc = get_accuracy(ground_truth,preds)\n",
    "print( f'Test accuracy: {test_acc}', f'Test loss: {eval_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('CyfroML')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23bb462f369faf32515ef68bcf08a22f46ef4bd3e7610215b17cb366918e9729"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
